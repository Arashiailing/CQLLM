import json

# ---------------- é…ç½® ----------------
dialogue_file = r"C:\code\CQLLM\v2.0\è®­ç»ƒæ•°æ®é›†\alpaca_dataset.jsonl"      # å¯¹è¯æ•°æ®é›†
completion_file = r"C:\code\CQLLM\v2.0\è®­ç»ƒæ•°æ®é›†\completion_dataset.jsonl" # è¡¥å…¨æ•°æ®é›†
output_file = r"C:\code\CQLLM\v2.0\è®­ç»ƒæ•°æ®é›†\dataset.jsonl"         # åˆå¹¶åçš„æ–‡ä»¶

# ---------------- å·¥å…·å‡½æ•° ----------------
def load_jsonl(path):
    data = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                try:
                    data.append(json.loads(line))
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON è§£æé”™è¯¯: {e} @ {path}")
    return data

# ---------------- ä¸»é€»è¾‘ ----------------
dialogue_data = load_jsonl(dialogue_file)
completion_data = load_jsonl(completion_file)

merged_data = dialogue_data + completion_data

# æ‰“ä¹±æ•°æ®é¡ºåºï¼ˆå¯é€‰ï¼‰
import random
random.shuffle(merged_data)

# ---------------- è¾“å‡º ----------------
with open(output_file, "w", encoding="utf-8") as f:
    for entry in merged_data:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

print(f"âœ… åˆå¹¶å®Œæˆ: {len(dialogue_data)} æ¡å¯¹è¯ + {len(completion_data)} æ¡è¡¥å…¨ = {len(merged_data)} æ¡")
print(f"ğŸ‘‰ è¾“å‡ºæ–‡ä»¶: {output_file}")
